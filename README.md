# Memory-Retaining Neural Networks
Repository for neural networks that retain memory from sequential data, such as RNN, LSTM, GRU, Bi-directional RNN, Encoder-Decoder, etc.

<ul type = "disc">

<li><b><h3>Simple RNN</h3></b></li>
Implemented a simple RNN neural network with forward and backward pass on time-series weather data.

<li><b><h3>Simple LSTM</h3></b></li>
Implemented a simple LSTM neural network on the Microsoft Stock Price Prediction dataset from Kaggle.

<li><b><h3>Bi-directional RNN</h3></b></li>
Implemented a bi-directional RNN neural network on the IMDB movie review dataset from Kaggle.
<br><br>
Dataset: [https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows](https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows)

<li><b><h3>Bi-directional LSTM</h3></b></li>
Implemented a bi-directional LSTM neural network on the IMDB movie review dataset, achieving 75% validation accuracy.

<li><b><h3>Gated Recurrent Unit (GRU)</h3></b></li>
Implemented a GRU neural network for the Date-Temperature dataset to predict the temperature for the next day based on past records.

<li><b><h3>Encoder-Decoder Sequence-to-Sequence Architecture</h3></b></li>
Implemented an Encoder-Decoder Seq2Seq architecture for English to Hindi translation. The model can be trained for more epochs to improve accuracy. This is just a basic implementation to showcase usecase.

</ul>
